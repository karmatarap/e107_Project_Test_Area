# Motivation

Adverse Drug Reactions (ADRs) are harmful effects caused by the intake of a medical drug and represent a significant societal health problem. According to the FDA Adverse Effects Reporting system the number of hospitalizations and even deaths caused by ADRs is ever increasing and has [reached over one million cases in the US as of 2014](http://www.fda.gov/Drugs/GuidanceComplianceRegulatoryInformation/Surveillance/AdverseDrugEffects/ucm070434.htm). This corresponds to [5% of hospital visits, 28% of emergency visits and 5% of hospital deaths](http://diego.asu.edu/Publications/ADRClassify.html).

Thus, the detection of these events plays a significant role for improving human health. The assessment and detection of adverse reactions for prescription drugs starts at the clinical trial level and continues after market release through national reporting tools that allow manufacturers and the public to report on ADRs. However, due to the limitations of clinical trials and the voluntary nature of public reporting tools, the actual detection of the adverse reactions is incomplete and not timely.

With the [massive increase of social media](http://www.pewinternet.org/fact-sheets/social-networking-fact-sheet/) usage over the past years, where patients share information about diseases, symptoms and treatments, social networks can represent an alternative source to identify ADRs from user generated data.

While social media offers new opportunities for health monitoring, it also brings about unique challenges. Due to its free-text nature, the data is rather unstructured and informal, containing a high level of misspellings or colloquialisms which makes natural language processing and algorithm applications difficult. Identifying ADRs terms is an additional challenge because often the information published can be irrelevant to an actual treatment or personal experience or it might even be commercial information about a drug. Additionaly, the effects of a drug mentioned can either be an adverse reaction or a beneficial one, and the diversity of informal terms used are hard to match with adverse effects lexicon terms.  
 
## Project goals

While different social platforms are used to exchange health information, such as communities, blogs, forums etc. for this project we chose to focus on twitter as a source for health-related information. There are [1.3 billion registered users and 310 million people that use Twitter with 120 million unique visitors per month](https://about.twitter.com/company). 

In the first place we wanted to investigate the possibilities for retrieving twitter data containing drug related information.

Considering the challenges of unstructured data we wanted to find ways of dealing with spelling errors, slang words, match with ADR lexicon terms, extracting hashtags and URLs. 

And lastly, we wanted investigate whether machine learning techniques trained on older data to predict an ADR can also be applied to current data. This question is of critical importance because if the language or content in social media change so drastically over few years that models trained on old data are not valid anymore, it  would mean that experts have to annotate quite large amounts of tweets on a regular basis to have valid training samples.

## Methodology

#### Data Collection

For the analysis we used both secondary as well as primary twitter data. 
As secondary data we used two twitter corpora collected from the paper by [Nikfarjam et al: 
Pharmacovigilance from social media: mining adverse drug reaction mentions using sequence labeling with word embedding cluster features](http://www.ncbi.nlm.nih.gov/pubmed/25755127) and from [Abeed Sarker and Graciela Gonzalez. Portable automatic text classification for adverse drug reaction detection via multi-corpus training. Journal of Biomedical Informatics. 53 (2015) 196-207.](http://diego.asu.edu/Publications/ADRClassify.html).
This data contained tweet ids and tweet annotations. We could then use the tweet id to retrieve the actual tweets using a python script provided by the authors. 

To collect primary twitter data the same drug list was used as in the paper by Nikfarjam et al. All tweets in english starting from January 2016 containing the listed drug names were been retrieved using Twitterâ€™s application programming interface and the R twitterR package.  


#### Data analysis

Using the secondary data we first investigated the proportion of ADR related words versus the non-ADR related words by doing exploratory data analysis using, e.g. wordclouds and sentiment analysis.

We then applied data cleaning methods to the existing and newly retrieved data:

+ replace slang expression and expressions using a dictionary
+ spellchecking and replacing words
+ more standard NLP techniques like word stemming
 
As a next step we applied machine learning techniques to investigate if models for predicting ADRs on data generated in 2013 still applied to data retrieved today. Different sets of features were explored:

+ Bag of words using term frequency
+ Bag of words using term frequency / inverse document frequency
+ sentiment analysis
+ wheter the tweet contains a URL (related to advertisments)
+ length of the tweet

To deal with this question we first trained models on the secondary data sets. We then applied the models to the primary data to validate the models. As an evaluation metric we chose to use area under curve, which is a fairly common measure.

## Results

The results on the secondary dataset were good (area under curve around 85%) and comparable to results mentioned in previous research. The data cleaning steps spell-checking and slang-replacement gave advantages over using just standard NLP techniques (especially on models before stacking: there they gave an improvement in AUC of around 5%, in the stacked model around 2%).
The results on the recent data were considerably lower. The most likely reason is that even manually annotating tweets is difficult and our methodology was different from the researchers' in the references.
