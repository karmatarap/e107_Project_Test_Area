---
title: "04_second_round"
author: "Alexander Noll"
date: "27 April 2016"
output: html_document
---

```{r 04_setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

# This package and the corresponding command makes sure, we all use the same
# versions of the packages
library(tidytext)
library(checkpoint)
checkpoint("2016-04-01")

library(plyr)

library(caret)
library(dplyr)
library(ggplot2)
library(ggthemes)
library(magrittr)
library(pROC)
library(purrr)
library(RColorBrewer)
library(RTextTools)
library(readr)
library(stringr)
library(tidyr)
library(tidytext)
library(tm)
library(wordcloud)

theme_set(theme_bw())

source("../r/helper_functions/parse_diego_data.R")
source("../r/helper_functions/parse-binary_data.R")

```

```{r 04_data_prep}
prep_data <- function() {
    # Prepares two tidy datasets: training set and test set
    #
    # Args: None
    #
    # Returns: list whose first entry is the training set and whose second
    #          entry is the test set
    
    # Read dataset that is annotated in detail
    train_data_annotated <- 
        parse_diego_data("train") %>%
        mutate(is_AE = as.factor(ifelse(!is.na(start_offset), "Yes", "No")))
    
    test_data_annotated <-
        parse_diego_data("test") %>%
        mutate(is_AE = as.factor(ifelse(!is.na(start_offset), "Yes", "No")))
    
    # Read binary annotated dataset
    binary_data <- parse_binary_data()
    binary_train_ind <- createDataPartition(binary_data$is_AE, p = 0.75, list = FALSE)
    
    # Bind two sets
    train_data <-
        bind_rows(train_data_annotated,
                  binary_data %>% slice(binary_train_ind)
                  ) %>% 
        select(tweet_id, user_id, tweet_text, is_AE) %>% 
        distinct(tweet_id) %>% 
        distinct(tweet_text)
    
    test_data <- 
        bind_rows(test_data_annotated,
                  binary_data %>% slice(-binary_train_ind)
                  )  %>% 
        select(tweet_id, user_id, tweet_text, is_AE)
    
    train_data$is_AE %<>% as.factor
    test_data$is_AE %<>% as.factor
        
    # Remove drugs from text
    drugs <- read_lines("../data/download_tweets/drug_names.txt", skip = 6)
    drug_regex <- drugs %>% str_c(collapse = "|") %>% str_c("(", ., ")")
    
    train_data$tweet_text %<>% str_to_lower %>%  str_replace_all(drug_regex, "")
    test_data$tweet_text %<>% str_to_lower %>%  str_replace_all(drug_regex, "")
    
    # Tidy data
    tidy_data <- function(data) {
        # Tidy data
        data %>% 
            distinct(tweet_id) %>% 
            mutate(tweet_text = stemDocument(tweet_text)) %>% 
            unnest_tokens(word, tweet_text)
    }
    
    tidy_train <- tidy_data(train_data)
    tidy_test <- tidy_data(test_data)
    
    # Compute Sentiments
    compute_sentiments <- function(data) {
        inner_join(data,
                   sentiments %>% select(word, sentiment) %>% distinct(),
                   by = "word") %>% 
            filter(!is.na(sentiment)) %>% 
            count(tweet_id, sentiment) %>% 
            mutate(sentiment = str_c("sentiment_", sentiment)) %>% 
            spread(sentiment, n)
    }
    
    sentiments_train <- compute_sentiments(tidy_train)
    sentiments_test <- compute_sentiments(tidy_test)
    
    # Documenttermmatrix / remove stopword
    compute_dtm <- function(data, min_freq = 7) {
        data %>% 
            anti_join(stop_words, by = "word") %>% 
            group_by(word) %>%
            filter(n() >= min_freq)  %>% 
            group_by(tweet_id, add = TRUE) %>% 
            summarise(count = n()) %>%
            ungroup() %>%
            spread(word, count, fill = 0) 
    }
    
    dtm_train <- compute_dtm(tidy_train)
    dtm_test <- compute_dtm(tidy_test)
    
    # Combine train
    train <-
        train_data %>% 
        select(tweet_id, is_AE) %>% 
        distinct() %>% 
        left_join(sentiments_train, by = "tweet_id") %>% 
        left_join(dtm_train, by = "tweet_id")
    
    # Combine test
    test <-
        test_data %>% 
        select(tweet_id, is_AE) %>% 
        distinct() %>% 
        left_join(sentiments_test, by = "tweet_id") %>% 
        left_join(dtm_test, by = "tweet_id")
    
    # For prediction purposes, we need all columns of the training set in the
    # test set
    test[, colnames(train)[!colnames(train) %in% colnames(test)]] <- 0
    
    train[is.na(train)] <- 0
    test[is.na(test)] <- 0
    
    list(train = train, test = test)

}

data <- prep_data()

```

```{r 04_fit_xgboost}
tr_control <- trainControl(method = "cv",
                           number = 3,
                           classProbs = TRUE,
                           summaryFunction = twoClassSummary)

tune_grid <- expand.grid(max_depth = c(7, 8, 9),
                         eta = c(0.3, 0.4, 0.5),
                         nrounds = c(200, 300, 400),
                         colsample_bytree = c(0.6, 0.8),
                         gamma = c(1, 2),
                         min_child_weight = c(1)
                         )

fit_xgb <- train(is_AE ~ .,
             data = data[[1]] %>% dplyr::select(-tweet_id),
             method = "xgbTree",
             trControl = tr_control,
             tuneGrid = tune_grid,
             metric = "ROC")

fit_xgb

```

```{r 04_fit_glmnet}
tr_control <- trainControl(method = "cv",
                           number = 3,
                           classProbs = TRUE,
                           summaryFunction = twoClassSummary)

tune_grid <- expand.grid(alpha = c(0, 0.5, 1),
                         lambda = c(0, 0.1, 0.01, 0.001)
                         )

fit_glm <- train(is_AE ~ .,
             data = data[[1]] %>% dplyr::select(-tweet_id),
             method = "glmnet",
             trControl = tr_control,
             tuneGrid = tune_grid,
             metric = "ROC")

fit_glm
```

```{r 04_fit_SVM}
tr_control <- trainControl(method = "cv",
                           number = 3,
                           classProbs = TRUE,
                           summaryFunction = twoClassSummary)

tune_grid <- expand.grid(sigma = c(0.1, 0.01),
                         C = c(1, 0.1)
                         )

fit_svm <- train(is_AE ~ .,
             data = data[[1]] %>% dplyr::select(-tweet_id),
             method = "svmRadial",
             trControl = tr_control,
             tuneGrid = tune_grid,
             metric = "ROC")

fit_svm
```

```{r 04_fit_nnet}
tr_control <- trainControl(method = "cv",
                           number = 3,
                           classProbs = TRUE,
                           summaryFunction = twoClassSummary)

tune_grid <- expand.grid(size = c(1, 3, 10),
                         decay = c(1, 0.1, 0.01)
                         )

fit_net <- train(is_AE ~ .,
             data = data[[1]] %>% dplyr::select(-tweet_id),
             method = "nnet",
             trControl = tr_control,
             tuneGrid = tune_grid,
             metric = "ROC")

fit_net
```

```{r }
data_cv <- 
    data[[2]] %>% 
    mutate(pred_xgb = predict(fit_xgb, newdata = ., type = "prob")[, 2],
           pred_glm = predict(fit_glm, newdata = ., type = "prob")[, 2],
           pred_svm = predict(fit_svm, newdata = ., type = "prob")[, 2],
           pred_net = predict(fit_net, newdata = ., type = "prob")[, 2]) %>% 
    dplyr::select(tweet_id, is_AE, starts_with("pred_"))
```

```{r}
super_learner <- train(is_AE ~ .,
                       data = data_cv %>% dplyr::select(-tweet_id),
                       method = "rf",
                       trControl = trainControl(method = "cv",
                                                number = 3,
                                                classProbs = TRUE,
                                                summaryFunction = twoClassSummary),
                       metric = "ROC")

super_learner
```

